{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb686168-f466-4730-b42d-84de40138d4d",
   "metadata": {},
   "source": [
    "# From TF to TF-lite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a47430-618a-46a6-b173-f640e92b05b0",
   "metadata": {},
   "source": [
    "## Download the Tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c240107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model and rename it\n",
    "!wget https://github.com/DataTalksClub/machine-learning-zoomcamp/releases/download/chapter7-model/xception_v4_large_08_0.894.h5 -O clothing-model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d77b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check python version\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52435019",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4225e13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-image-helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743b5fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --extra-index-url https://google-coral.github.io/py-repo/ tflite_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f422a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 11:57:41.785859: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-12 11:57:44.835295: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-12 11:57:45.841880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-12 11:57:48.000527: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-12 11:57:48.324010: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-12 11:57:51.762348: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-12 11:58:07.612054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary import\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.lite as tflite\n",
    "# import tflite_runtime.interpreter as tflite_int # to avoid depending on tensorflow\n",
    "\n",
    "# Check tensorflow version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe41c53-7711-4605-bfa9-8b15aed2a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary import\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from keras_image_helper import create_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cff12e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-12 10:56:53--  http://bit.ly/mlbookcamp-pants\n",
      "Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10, 64:ff9b::43c7:f80a, ...\n",
      "Connecting to bit.ly (bit.ly)|67.199.248.11|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://raw.githubusercontent.com/alexeygrigorev/clothing-dataset-small/master/test/pants/4aabd82c-82e1-4181-a84d-d0c6e550d26d.jpg [following]\n",
      "--2024-12-12 10:56:54--  https://raw.githubusercontent.com/alexeygrigorev/clothing-dataset-small/master/test/pants/4aabd82c-82e1-4181-a84d-d0c6e550d26d.jpg\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23048 (23K) [image/jpeg]\n",
      "Saving to: ‘pants.jpg’\n",
      "\n",
      "pants.jpg           100%[===================>]  22.51K  --.-KB/s    in 0.07s   \n",
      "\n",
      "2024-12-12 10:56:56 (324 KB/s) - ‘pants.jpg’ saved [23048/23048]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download a pants' image\n",
    "!wget http://bit.ly/mlbookcamp-pants -O pants.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe2b29c-4936-4947-8e16-547cac84ccb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d911b5ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Error when deserializing class 'SeparableConv2D' using config={'name': 'block2_sepconv1', 'trainable': False, 'dtype': 'float32', 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'activation': 'linear', 'use_bias': False, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'pointwise_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'depthwise_regularizer': None, 'pointwise_regularizer': None, 'depthwise_constraint': None, 'pointwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to SeparableConv2D: {'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'kernel_regularizer': None, 'kernel_constraint': None}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/ops/operation.py:234\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/layers/convolutional/separable_conv2d.py:122\u001b[0m, in \u001b[0;36mSeparableConv2D.__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, depth_multiplier, activation, use_bias, depthwise_initializer, pointwise_initializer, bias_initializer, depthwise_regularizer, pointwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, pointwise_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    101\u001b[0m     filters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    121\u001b[0m ):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    123\u001b[0m         rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    124\u001b[0m         depth_multiplier\u001b[38;5;241m=\u001b[39mdepth_multiplier,\n\u001b[1;32m    125\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[1;32m    126\u001b[0m         kernel_size\u001b[38;5;241m=\u001b[39mkernel_size,\n\u001b[1;32m    127\u001b[0m         strides\u001b[38;5;241m=\u001b[39mstrides,\n\u001b[1;32m    128\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m    129\u001b[0m         data_format\u001b[38;5;241m=\u001b[39mdata_format,\n\u001b[1;32m    130\u001b[0m         dilation_rate\u001b[38;5;241m=\u001b[39mdilation_rate,\n\u001b[1;32m    131\u001b[0m         activation\u001b[38;5;241m=\u001b[39mactivation,\n\u001b[1;32m    132\u001b[0m         use_bias\u001b[38;5;241m=\u001b[39muse_bias,\n\u001b[1;32m    133\u001b[0m         depthwise_initializer\u001b[38;5;241m=\u001b[39mdepthwise_initializer,\n\u001b[1;32m    134\u001b[0m         pointwise_initializer\u001b[38;5;241m=\u001b[39mpointwise_initializer,\n\u001b[1;32m    135\u001b[0m         bias_initializer\u001b[38;5;241m=\u001b[39mbias_initializer,\n\u001b[1;32m    136\u001b[0m         depthwise_regularizer\u001b[38;5;241m=\u001b[39mdepthwise_regularizer,\n\u001b[1;32m    137\u001b[0m         pointwise_regularizer\u001b[38;5;241m=\u001b[39mpointwise_regularizer,\n\u001b[1;32m    138\u001b[0m         bias_regularizer\u001b[38;5;241m=\u001b[39mbias_regularizer,\n\u001b[1;32m    139\u001b[0m         activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer,\n\u001b[1;32m    140\u001b[0m         depthwise_constraint\u001b[38;5;241m=\u001b[39mdepthwise_constraint,\n\u001b[1;32m    141\u001b[0m         pointwise_constraint\u001b[38;5;241m=\u001b[39mpointwise_constraint,\n\u001b[1;32m    142\u001b[0m         bias_constraint\u001b[38;5;241m=\u001b[39mbias_constraint,\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    144\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/layers/convolutional/base_separable_conv.py:104\u001b[0m, in \u001b[0;36mBaseSeparableConv.__init__\u001b[0;34m(self, rank, depth_multiplier, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, depthwise_initializer, pointwise_initializer, bias_initializer, depthwise_regularizer, pointwise_regularizer, bias_regularizer, activity_regularizer, depthwise_constraint, pointwise_constraint, bias_constraint, trainable, name, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     80\u001b[0m     rank,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    103\u001b[0m ):\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    105\u001b[0m         trainable\u001b[38;5;241m=\u001b[39mtrainable,\n\u001b[1;32m    106\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    107\u001b[0m         activity_regularizer\u001b[38;5;241m=\u001b[39mregularizers\u001b[38;5;241m.\u001b[39mget(activity_regularizer),\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m=\u001b[39m rank\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/layers/layer.py:285\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Will be determined in `build_wrapper`\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to SeparableConv2D: {'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'kernel_regularizer': None, 'kernel_constraint': None}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the model`\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclothing-model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/saving/saving_api.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    190\u001b[0m         filepath,\n\u001b[1;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    194\u001b[0m     )\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[1;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/legacy/saving/legacy_h5_format.py:133\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    130\u001b[0m model_config \u001b[38;5;241m=\u001b[39m json_utils\u001b[38;5;241m.\u001b[39mdecode(model_config)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m saving_options\u001b[38;5;241m.\u001b[39mkeras_option_scope(use_legacy_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 133\u001b[0m     model \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[1;32m    134\u001b[0m         model_config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    135\u001b[0m     )\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[1;32m    138\u001b[0m     load_weights_from_hdf5_group(f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m], model)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m     86\u001b[0m     config,\n\u001b[1;32m     87\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mMODULE_OBJECTS\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m     88\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m     89\u001b[0m     printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:495\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    490\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(\n\u001b[1;32m    491\u001b[0m     cls_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[0;32m--> 495\u001b[0m     deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(\n\u001b[1;32m    496\u001b[0m         cls_config,\n\u001b[1;32m    497\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    498\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mobject_registration\u001b[38;5;241m.\u001b[39mGLOBAL_CUSTOM_OBJECTS,\n\u001b[1;32m    499\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom_objects,\n\u001b[1;32m    500\u001b[0m         },\n\u001b[1;32m    501\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/models/model.py:527\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional_from_config(\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/models/functional.py:546\u001b[0m, in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 546\u001b[0m     process_layer(layer_data)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/models/functional.py:514\u001b[0m, in \u001b[0;36mfunctional_from_config.<locals>.process_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_data:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m# used for H5 and SavedModel formats\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     layer \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[1;32m    515\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    516\u001b[0m     )\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     layer \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    519\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    520\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m     86\u001b[0m     config,\n\u001b[1;32m     87\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mMODULE_OBJECTS\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m     88\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m     89\u001b[0m     printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:495\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    490\u001b[0m cls_config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(\n\u001b[1;32m    491\u001b[0m     cls_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    492\u001b[0m )\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom_objects\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec\u001b[38;5;241m.\u001b[39margs:\n\u001b[0;32m--> 495\u001b[0m     deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(\n\u001b[1;32m    496\u001b[0m         cls_config,\n\u001b[1;32m    497\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m    498\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mobject_registration\u001b[38;5;241m.\u001b[39mGLOBAL_CUSTOM_OBJECTS,\n\u001b[1;32m    499\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom_objects,\n\u001b[1;32m    500\u001b[0m         },\n\u001b[1;32m    501\u001b[0m     )\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/models/model.py:527\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[1;32m    524\u001b[0m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[0;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m functional_from_config(\n\u001b[1;32m    528\u001b[0m         \u001b[38;5;28mcls\u001b[39m, config, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/models/functional.py:546\u001b[0m, in \u001b[0;36mfunctional_from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# First, we create all layers and enqueue nodes to be processed\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_data \u001b[38;5;129;01min\u001b[39;00m functional_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayers\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 546\u001b[0m     process_layer(layer_data)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# Then we process nodes in order of layer depth.\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;66;03m# Nodes that cannot yet be processed (if the inbound node\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# does not yet exist) are re-enqueued, and the process\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# is repeated until all nodes are processed.\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m unprocessed_nodes:\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/models/functional.py:514\u001b[0m, in \u001b[0;36mfunctional_from_config.<locals>.process_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Instantiate layer.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m layer_data:\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# Legacy format deserialization (no \"module\" key)\u001b[39;00m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m# used for H5 and SavedModel formats\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     layer \u001b[38;5;241m=\u001b[39m saving_utils\u001b[38;5;241m.\u001b[39mmodel_from_config(\n\u001b[1;32m    515\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    516\u001b[0m     )\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     layer \u001b[38;5;241m=\u001b[39m serialization_lib\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    519\u001b[0m         layer_data, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects\n\u001b[1;32m    520\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/legacy/saving/saving_utils.py:85\u001b[0m, in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[1;32m     83\u001b[0m config \u001b[38;5;241m=\u001b[39m _find_replace_nested_dict(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serialization\u001b[38;5;241m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m     86\u001b[0m     config,\n\u001b[1;32m     87\u001b[0m     module_objects\u001b[38;5;241m=\u001b[39mMODULE_OBJECTS\u001b[38;5;241m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m     88\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m     89\u001b[0m     printable_module_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/legacy/saving/serialization.py:504\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m object_registration\u001b[38;5;241m.\u001b[39mCustomObjectScope(custom_objects):\n\u001b[0;32m--> 504\u001b[0m             deserialized_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_config(cls_config)\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;66;03m# Then `cls` may be a function returning a class.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;66;03m# in this case by convention `config` holds\u001b[39;00m\n\u001b[1;32m    508\u001b[0m     \u001b[38;5;66;03m# the kwargs of the function.\u001b[39;00m\n\u001b[1;32m    509\u001b[0m     custom_objects \u001b[38;5;241m=\u001b[39m custom_objects \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/keras/src/ops/operation.py:236\u001b[0m, in \u001b[0;36mOperation.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError when deserializing class \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mException encountered: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    239\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Error when deserializing class 'SeparableConv2D' using config={'name': 'block2_sepconv1', 'trainable': False, 'dtype': 'float32', 'filters': 128, 'kernel_size': [3, 3], 'strides': [1, 1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1, 1], 'activation': 'linear', 'use_bias': False, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None, 'depth_multiplier': 1, 'depthwise_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'pointwise_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'depthwise_regularizer': None, 'pointwise_regularizer': None, 'depthwise_constraint': None, 'pointwise_constraint': None}.\n\nException encountered: Unrecognized keyword arguments passed to SeparableConv2D: {'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'kernel_regularizer': None, 'kernel_constraint': None}"
     ]
    }
   ],
   "source": [
    "# Load the model`\n",
    "model = keras.models.load_model('clothing-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51863ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "img = load_img('pants.jpg', target_size = (299, 299))\n",
    "\n",
    "# Check the image\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d85cf8-e93c-4bdc-bbc1-28b99f56f96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a numpy array\n",
    "x = np.array(img)\n",
    "# Batch of 1 image\n",
    "X = np.array([x])\n",
    "\n",
    "# Preprocess input batch\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f971fb-9b77-403f-a130-b3c657f4d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the batch\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c759646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction\n",
    "preds = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8e063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the predictions\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09565d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target classes\n",
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "# Classes and correponding probabilities\n",
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50149c7f",
   "metadata": {},
   "source": [
    "## Convert Keras to TF-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898dc5cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize converter for the tf model\n",
    "converter = tflite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Convert to a tf-lite model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the converted model as a binary file\n",
    "with open('clothing-model.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list files to find the conerted model\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536f5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "interpreter = tflite.Interpreter(model_path = 'clothing-model.tflite')\n",
    "# Load the weights from the model to memory (necessary with tf-lite models)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Specify the input\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "# Specify the output\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the input of the interpreter\n",
    "interpreter.set_tensor(input_index, X)\n",
    "# Invoke computations in the neural network\n",
    "interpreter.invoke()\n",
    "# Fetch predictions\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d579e000-bc11-420f-b4e3-2f7d8dba16e6",
   "metadata": {},
   "source": [
    "Note that we are using the input batch `X`, that was preprocessed with the function `preprocess_input()`, and previously loaded using `load_img()`, both from `tensorflow`. We need to remove these tensorflow depenedencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6403dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target classes\n",
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "# Classes and predicted probabilities \n",
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50e64ac",
   "metadata": {},
   "source": [
    "## Removing TF dependency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55976f91-4cdb-437a-9681-e5422fac2884",
   "metadata": {},
   "source": [
    "We use `Image` from the library `PIL` to load the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e25a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read pants' image, resizing it\n",
    "with Image.open('pants.jpg') as img:\n",
    "    img = img.resize((299, 299), Image.NEAREST)\n",
    "\n",
    "# Visualize the image\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06c8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the input batch of images\n",
    "def preprocess_input(x):\n",
    "    x /= 127.5\n",
    "    x -= 1.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bf48c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to a numpy array\n",
    "x = np.array(img, dtype = 'float32')\n",
    "# Batch of 1 image\n",
    "X = np.array([x])\n",
    "\n",
    "# Preprocess input batch\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656b5981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the input of the interpreter\n",
    "interpreter.set_tensor(input_index, X)\n",
    "# Invoke computations in the neural network\n",
    "interpreter.invoke()\n",
    "# Fetch predictions\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9bb26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target classes\n",
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "# Classes and predicted probabilities \n",
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb1469-1df5-4e7b-bcd7-8d94d9ffc8d4",
   "metadata": {},
   "source": [
    "Now we do not have any dependency on tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfb17f7",
   "metadata": {},
   "source": [
    "## Simpler way of doing it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d9b97-23c5-4dda-893e-31e9584078a5",
   "metadata": {},
   "source": [
    "We can use the function `create_preprocessor` from the library `keras_image_helper`. Note that instead of importing `tf-lite` from `tf`, we imported ` tflite_runtime.interpreter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5903956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "interpreter = tflite_int.Interpreter(model_path = 'clothing-model.tflite')\n",
    "# Load the weights from the model to memory (necessary with tf-lite models)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Specify the input\n",
    "input_index = interpreter.get_input_details()[0]['index']\n",
    "# Specify the output\n",
    "output_index = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data preprocessor\n",
    "preprocessor = create_preprocessor('xception', target_size = (299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81622bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image url\n",
    "url = 'http://bit.ly/mlbookcamp-pants'\n",
    "# preprocess image\n",
    "X = preprocessor.from_url(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2189bd-0e46-4a5f-8ecb-df1f52dc102f",
   "metadata": {},
   "source": [
    "Note that we don't even have to download the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811511aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the input of the interpreter\n",
    "interpreter.set_tensor(input_index, X)\n",
    "# Invoke computations in the neural network\n",
    "interpreter.invoke()\n",
    "# Fetch predictions\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c925c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target classes\n",
    "classes = [\n",
    "    'dress',\n",
    "    'hat',\n",
    "    'longsleeve',\n",
    "    'outwear',\n",
    "    'pants',\n",
    "    'shirt',\n",
    "    'shoes',\n",
    "    'shorts',\n",
    "    'skirt',\n",
    "    't-shirt'\n",
    "]\n",
    "\n",
    "# Classes and predicted probabilities \n",
    "dict(zip(classes, preds[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0e6daa-33f3-4335-a278-475bd157be2f",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
